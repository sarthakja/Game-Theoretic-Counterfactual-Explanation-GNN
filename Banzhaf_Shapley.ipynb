{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kol6h58g-BUF"
      },
      "source": [
        "# Shapley Value Explainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Ko1R8z96BU"
      },
      "source": [
        "## Installing the packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqynIVa0-X_g",
        "outputId": "6755bb28-66c0-4ad7-de52-c1cdff5c58c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch Version: 2.1.0+cu121\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.3.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.0\n",
            "Collecting dgl\n",
            "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata>=0.5.0->dgl) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-2.1.0\n"
          ]
        }
      ],
      "source": [
        "# Make the `checkpoints` directory if it doesn't exist\n",
        "import pathlib\n",
        "import time\n",
        "pathlib.Path('/content/checkpoints').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Import the libs\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(\"Pytorch Version:\", torch.__version__)\n",
        "\n",
        "# Installing a few additional libs\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "\n",
        "# Install Pytorch Geometric\n",
        "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "! pip install torch_geometric\n",
        "\n",
        "#Installing DGL\n",
        "!pip install dgl\n",
        "import numpy as np\n",
        "from torch_geometric.utils import subgraph, k_hop_subgraph, degree, mask_to_index\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from itertools import chain, combinations\n",
        "from random import sample\n",
        "from random import choice\n",
        "from random import randint\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHzw9E9W-Zgp"
      },
      "source": [
        "## Dataset setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM9iKWvW-fEE",
        "outputId": "0667d06a-e7cf-4f90-bd9c-30c6f6e8df9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Explanation(edge_index=[2, 3964], y=[700], edge_mask=[3964], node_mask=[700], x=[700, 1])\n",
            "tensor([[  0,   0,   0,  ..., 699, 104, 698],\n",
            "        [  1,   2,  12,  ..., 696, 698, 104]])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0])\n",
            "***************\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.datasets import BAShapes\n",
        "from torch_geometric.nn import GCN\n",
        "from torch_geometric.datasets import ExplainerDataset\n",
        "from torch_geometric.datasets.graph_generator import BAGraph\n",
        "import torch_geometric.transforms as T\n",
        "from dgl.data import TreeCycleDataset\n",
        "from torch_geometric.utils import from_networkx\n",
        "from torch_geometric.utils import from_dgl\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from dgl.data import TreeGridDataset\n",
        "\n",
        "#Load the BAShapes Dataset\n",
        "dataset = ExplainerDataset(\n",
        "    graph_generator=BAGraph(num_nodes=300, num_edges=5),\n",
        "    motif_generator='house',\n",
        "    num_motifs=80,\n",
        "    transform=T.Constant(),\n",
        ")\n",
        "data = dataset[0]\n",
        "\n",
        "############## Code block to Load TreeCycle and TreeGrid Datasets###########\n",
        "#Use the appropriate line from the 2 subsequent lines depending on whether TreeCycle or TreeGrid dataset is required\n",
        "# dataset = TreeCycleDataset()\n",
        "# #dataset = TreeGridDataset()\n",
        "\n",
        "# data = dataset[0]\n",
        "# data = from_dgl(data)\n",
        "\n",
        "# data['y'] = data['label']\n",
        "# data['x'] = data['feat']\n",
        "# del(data['feat'])\n",
        "# del(data['label'])\n",
        "# data = ToUndirected()(data)\n",
        "# print(data.is_directed())\n",
        "######################################################################\n",
        "\n",
        "# Printing out the dataset\n",
        "print(data)\n",
        "#print(data.x)\n",
        "print(data.edge_index)\n",
        "print((data.y)[200:300])\n",
        "print(\"***************\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VAh47DrqPQW"
      },
      "outputs": [],
      "source": [
        "#This function is used to add random noise to the graph. Random noise means adding edges randomly to nodes that don't have any edge between them.\n",
        "\n",
        "#Parameter:\n",
        "# add_ratio: The fraction of existing count of edges to be added to the graph.\n",
        "def add_noise(add_ratio):\n",
        "  edgeIndexTransposed = torch.transpose(data.edge_index, 0 ,1)\n",
        "  edgeIndexNumpy = edgeIndexTransposed.numpy()\n",
        "  edgeIndexList = list(map(tuple, edgeIndexNumpy))\n",
        "  edgeIndexSet = set(edgeIndexList) #Set of tuples(each tuple is an edge)\n",
        "\n",
        "  #No of edges to add\n",
        "  edgesToAdd = int(add_ratio*len(edgeIndexSet))/2\n",
        "\n",
        "  edgesAdded = 0 #edges actually added\n",
        "  while(edgesAdded < edgesToAdd):\n",
        "    nodeList = sample(range((data.x.size())[0]),k = 2 )\n",
        "    nodeList = tuple(nodeList)\n",
        "    if(nodeList not in edgeIndexSet):\n",
        "      edgeIndexSet.add(nodeList)\n",
        "      reversedEdge = tuple(reversed(nodeList))\n",
        "      edgeIndexSet.add(reversedEdge)\n",
        "      edgesAdded+=1\n",
        "\n",
        "  edgeIndexArray = np.array(list(edgeIndexSet))\n",
        "  edgeIndexArray = np.transpose(edgeIndexArray)\n",
        "  edgeIndexTensor = torch.from_numpy(edgeIndexArray)\n",
        "  data.edge_index = edgeIndexTensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uncomment the lines below to call the add_noise function to add random noise"
      ],
      "metadata": {
        "id": "lW1BrG96BWoG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZrQyyR4vU0S"
      },
      "outputs": [],
      "source": [
        "# noise_ratio = 0.1 # Adding 10% noise\n",
        "# add_noise(noise_ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Printing out data after adding random noise. Uncomment the lines below to print data after adding random noise"
      ],
      "metadata": {
        "id": "pr0nEOAQBoK9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K-b4yE5qOEk",
        "outputId": "df868fa7-2481-4582-b9c5-5bf637bb6ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation(edge_index=[2, 4756], y=[700], edge_mask=[3964], node_mask=[700], x=[700, 1])\n",
            "tensor([[ 61, 318,  84,  ..., 129, 506, 348],\n",
            "        [653, 315, 148,  ...,  34, 509,  72]])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0])\n",
            "***************\n"
          ]
        }
      ],
      "source": [
        "# print(data)\n",
        "# print(data.edge_index)\n",
        "# print((data.y)[200:300])\n",
        "# print(\"***************\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5Z-Gx9Z-9v0",
        "outputId": "3123b1e8-7630-4dca-985b-2f378b65d3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzZivS4b9wMk"
      },
      "source": [
        "# Saving and loading the noisy graph This cell stores the noisy graph in a pickle file, so that the same graph can be used across different runs of this notebook. Uncomment the lines below if you want to compare results by tweaking other parts of the model(such as the number of coalitions sampled for Banzhaf index) while keeping the graph constant. Make sure to replace the \"PATH_OF_FILE_THAT_WILL_HOLD_THE_NOISY_GRAPH\" with the appropriate path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1krfs9LmwOA"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# path = '/content/drive/MyDrive/'\n",
        "# file = open(path + <PATH_OF_FILE_THAT_WILL_HOLD_THE_NOISY_GRAPH>, 'wb')\n",
        "# pickle.dump(data, file)\n",
        "# file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uncomment the lines below to load the noisy graph. Make sure to replace the \"PATH_OF_FILE_THAT_HOLDS_THE_NOISY_GRAPH\" with the appropriate path."
      ],
      "metadata": {
        "id": "DyFTxGxsCPvW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4wO8yyB_9_7"
      },
      "outputs": [],
      "source": [
        "# # open the file, where you stored the noisy graph\n",
        "# path = '/content/drive/MyDrive/'\n",
        "# file = open(path + <PATH_OF_FILE_THAT_HOLDS_THE_NOISY_GRAPH>, 'rb')\n",
        "\n",
        "# # load information from that file\n",
        "# data = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCnCN5OFR3w-",
        "outputId": "622ba41c-484e-40c9-f4cf-80e3a84d9e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explanation(edge_index=[2, 4366], y=[700], edge_mask=[3970], node_mask=[700], x=[700, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9254WpFJunB"
      },
      "source": [
        "# Setup for edge mask. This is utilized for efficient calculation of Shapley and Banzhaf Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1NSwACrxePj"
      },
      "outputs": [],
      "source": [
        "edge_index_tp = torch.transpose(data.edge_index, 0 ,1)\n",
        "edge_index_np = edge_index_tp.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvoBS4UUSRGk"
      },
      "outputs": [],
      "source": [
        "ls = list(map(tuple, edge_index_np))\n",
        "tuple_edge_index = np.empty(len(ls), dtype=object)\n",
        "tuple_edge_index[:] = ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0EjsCAQ-feE"
      },
      "source": [
        "# Simple node classifier\n",
        "\n",
        "We are explaining the GCN model here, although our proposed method can be used to explain any model, it does not depend on the GNN. However, it is important that the model performs well on the node classification task for our explanation method to work well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYqDLfi_4oTG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.nn import GCNConv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqJbhWSQmyUZ"
      },
      "source": [
        "# Train and Test methods. The GCN model hyperparameters are different for BAShapes v/s TreeCycles and TreeGrid. See the cell below, and uncomment the appropriate lines according to whether BAShapes is being evaluated or TreeCycle/TreeGrid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3TAi69zI1bO",
        "outputId": "f6866a27-2b74-4dae-a011-1638aaf2fc23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.6112, Train: 0.7875, Test: 0.8500: 100%|██████████| 4000/4000 [00:19<00:00, 210.14it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GCN(1, 4, num_layers=3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# from IPython.display import Javascript  # Restrict height of output cell.\n",
        "# display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "data = data.to(\"cpu\")\n",
        "idx = torch.arange(data.num_nodes)\n",
        "train_idx, test_idx = train_test_split(idx, train_size=0.8, stratify=data.y)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#For BAShapes\n",
        "model = GCN(data.num_node_features, hidden_channels=20, num_layers=3,\n",
        "            out_channels=dataset.num_classes)\n",
        "\n",
        "#For TreeCycles and TreeGrid:\n",
        "# model = GCN(data.num_node_features, hidden_channels=128, num_layers=2,\n",
        "#             out_channels=dataset.num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "data = data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.005)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.cross_entropy(out[train_idx], data.y[train_idx])\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    pred = model(data.x, data.edge_index).argmax(dim=-1)\n",
        "\n",
        "    train_correct = int((pred[train_idx] == data.y[train_idx]).sum())\n",
        "    train_acc = train_correct / train_idx.size(0)\n",
        "\n",
        "    test_correct = int((pred[test_idx] == data.y[test_idx]).sum())\n",
        "    test_acc = test_correct / test_idx.size(0)\n",
        "\n",
        "    return train_acc, test_acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uncomment the lines below to train the GCN. This portion is kept commented to train the model only once, and then save the trained state for further use.\n",
        "\n"
      ],
      "metadata": {
        "id": "HW7QjPMCDRbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# pbar = tqdm(range(1, 4001))\n",
        "# for epoch in pbar:\n",
        "#     loss = train()\n",
        "#     if epoch == 1 or epoch % 200 == 0:\n",
        "#         train_acc, test_acc = test()\n",
        "#         pbar.set_description(f'Loss: {loss:.4f}, Train: {train_acc:.4f}, '\n",
        "#                              f'Test: {test_acc:.4f}')\n",
        "# pbar.close()\n",
        "# model.eval()"
      ],
      "metadata": {
        "id": "Idot8fjLDZRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.to(device)"
      ],
      "metadata": {
        "id": "J_lc43y4V8tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uncomment the lines below to save the trained model. You may want to save different versions of the model: model saved on noisy graph, and model saved on graph without noise. Make sure to replace \"PATH_TO_FILE_THAT_HOLDS_THE_SAVED_MODEL\" with the appropriate path"
      ],
      "metadata": {
        "id": "aEb3lxIyDgAs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zW8Z14QjKe1r"
      },
      "outputs": [],
      "source": [
        "# path = '/content/drive/MyDrive/'\n",
        "# file = open(path + <PATH_TO_FILE_THAT_HOLDS_THE_SAVED_MODEL>, 'wb')\n",
        "# torch.save(model, file)\n",
        "# file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the saved model. Make sure to replace the \"PATH_TO_FILE_THAT_HOLDS_THE_SAVED_MODEL\" with the appropriate path."
      ],
      "metadata": {
        "id": "IOLL4TBPDtvS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGEAgJCwyB2m"
      },
      "outputs": [],
      "source": [
        "# open a file, where you stored the saved model\n",
        "path = '/content/drive/MyDrive/'\n",
        "file = open(path + <PATH_TO_FILE_THAT_HOLDS_THE_SAVED_MODEL>, 'rb')\n",
        "\n",
        "\n",
        "# dump information to that file\n",
        "model = torch.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEa_k_9qHr55"
      },
      "source": [
        "## Test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4vSobZF4tOS",
        "outputId": "54423367-aa77-4333-a889-860d232343eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The train acc is:  0.7875  and the test acc is:  0.85\n"
          ]
        }
      ],
      "source": [
        "train_acc, test_acc = test()\n",
        "print(\"The train acc is: \", train_acc, \" and the test acc is: \", test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIePn8tk-12l"
      },
      "source": [
        "# Explainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ioBOPSkuC65"
      },
      "source": [
        "## Some Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIoRJSpDqiyY"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.utils import subgraph, k_hop_subgraph, degree, mask_to_index\n",
        "from torch_geometric.nn.conv import edge_conv\n",
        "\n",
        "#Returns hop_size_k hop subgraph around the node node_id\n",
        "def get_edges(data, node_id, hop_size_k):\n",
        "  #print(\"In get_edges, hop size is: \", hop_size_k)\n",
        "  return k_hop_subgraph(node_idx = node_id, num_hops = hop_size_k, edge_index = data.edge_index)\n",
        "\n",
        "#Returns class probabilities(a vector) and predicted class for node node_id.\n",
        "def get_node_class_prob (node_id, edge_ind):\n",
        "  model.eval()\n",
        "  edge_ind = edge_ind.to(device)\n",
        "  out = model(data.x, edge_ind)\n",
        "  pred = out.argmax(dim=-1)\n",
        "  probs = F.softmax(out, dim=-1).detach()\n",
        "  return probs[node_id], pred[node_id].item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "x4pdzID7uN50",
        "outputId": "540a2508-bd10-47ef-c289-fda4f95666b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef get_change_in_class_prob_for_set_of_edges_orig (node_id, hard_set_of_edges):\\n  # get original classification\\n  model.eval()\\n  original_prob_vector, original_class = get_node_class_prob(node_id, data.edge_index)\\n  original_prob = original_prob_vector[original_class].item()\\n  edge_index = data.edge_index\\n\\n  set_of_edges = list(list(i) for i in hard_set_of_edges)\\n  #remove edges and get new classification\\n  edge_index = remove_set_of_edges(edge_index, set_of_edges)\\n  changed_prob_vector, changed_class = get_node_class_prob(node_id, edge_index)\\n  changed_prob = changed_prob_vector[original_class].item()\\n\\n  #put back edges\\n  edge_index = add_set_of_edges(edge_index, set_of_edges)\\n  return original_prob - changed_prob\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#Calculates the change in probability for node_id after removing the set of edges given by hard_set_of_edges\n",
        "def get_change_in_class_prob_for_set_of_edges (node_id, hard_set_of_edges):\n",
        "  # get original classification\n",
        "  model.eval()\n",
        "  original_prob_vector, original_class = get_node_class_prob(node_id, data.edge_index)\n",
        "  original_prob = original_prob_vector[original_class].item()\n",
        "  edge_index = data.edge_index\n",
        "\n",
        "  set_of_edges = list(i for i in hard_set_of_edges)\n",
        "  set_of_edges = set(set_of_edges)\n",
        "  def generate_mask(arr_ele):\n",
        "    return not(arr_ele in set_of_edges or tuple(reversed(arr_ele)) in set_of_edges)\n",
        "\n",
        "  # Generate mask\n",
        "  vectorized_mask_method = np.vectorize(generate_mask)\n",
        "  mask_arr = vectorized_mask_method(tuple_edge_index)\n",
        "\n",
        "  # Filter the edge_index_np(numpy array of the transposed edge_index) based on the mask generated above and convert it into a pytorch tensor\n",
        "  filtered_edge_index = edge_index_np[mask_arr]\n",
        "  filtered_edge_index = np.transpose(filtered_edge_index)\n",
        "  filtered_edge_index = torch.from_numpy(filtered_edge_index)\n",
        "\n",
        "  #remove edges and get new classification\n",
        "  #edge_index = remove_set_of_edges(edge_index, set_of_edges)\n",
        "  changed_prob_vector, changed_class = get_node_class_prob(node_id, filtered_edge_index)\n",
        "  changed_prob = changed_prob_vector[original_class].item()\n",
        "\n",
        "  #put back edges\n",
        "  #edge_index = add_set_of_edges(edge_index, set_of_edges)\n",
        "  return original_prob - changed_prob\n",
        "\n",
        "# Calculates if the predicted class changes for node_id after removing the set of edges given by hard_set_of_edges. If the class changes, then the return\n",
        "# value is 0, otherwise 1. hard_set_of_edges is a collection of edges where each edge is represented as a tuple.\n",
        "def get_change_in_class_for_set_of_edges (node_id, hard_set_of_edges):\n",
        "  # get original classification\n",
        "  model.eval()\n",
        "  original_prob_vector, original_class = get_node_class_prob(node_id, data.edge_index)\n",
        "  original_prob = original_prob_vector[original_class].item()\n",
        "  edge_index = data.edge_index\n",
        "\n",
        "  set_of_edges = list(i for i in hard_set_of_edges)\n",
        "  set_of_edges = set(set_of_edges)\n",
        "  def generate_mask(arr_ele):\n",
        "    return not(arr_ele in set_of_edges or tuple(reversed(arr_ele)) in set_of_edges)\n",
        "\n",
        "  # Generate mask\n",
        "  vectorized_mask_method = np.vectorize(generate_mask)\n",
        "  mask_arr = vectorized_mask_method(tuple_edge_index)\n",
        "\n",
        "  # Filter the edge_index_np(numpy array of the transposed edge_index) based on the mask generated above and convert it into a pytorch tensor\n",
        "  filtered_edge_index = edge_index_np[mask_arr]\n",
        "  filtered_edge_index = np.transpose(filtered_edge_index)\n",
        "  filtered_edge_index = torch.from_numpy(filtered_edge_index)\n",
        "\n",
        "  #remove edges and get new classification\n",
        "  #edge_index = remove_set_of_edges(edge_index, set_of_edges)\n",
        "  changed_prob_vector, changed_class = get_node_class_prob(node_id, filtered_edge_index)\n",
        "  changed_prob = changed_prob_vector[original_class].item()\n",
        "\n",
        "  #put back edges\n",
        "  #edge_index = add_set_of_edges(edge_index, set_of_edges)\n",
        "  return (original_prob - changed_prob, original_class == changed_class)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsO-mVrDu6r5"
      },
      "source": [
        "# Set the following hyperparameters in the cell below:\n",
        "\n",
        "**Budget**: The no of edges given out as the explanation\n",
        "\n",
        "**HOP_SIZE**: The no of hops up to which an edge is considered as a candidate for explanation  \n",
        "\n",
        "**Coalition_Count**: The no of coalitions to be considered when calculating the Banzhaf value.\n",
        "\n",
        "**THRESHOLD**: The threshold parameter in our paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_z7EbMgw_pA"
      },
      "outputs": [],
      "source": [
        "BUDGET = \"JUNK\" # No of explanation edges returned for each node\n",
        "HOP_SIZE = 1 # The no of hops upto which the edges for a node are considered\n",
        "Coalition_Count = 1500 # Parameter of banzhaf index: No of total coalitions considered from which the critical voters are considered\n",
        "THRESHOLD = \"JUNK\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to compute the Banzhaf Value. The implementation is based on the paper: [Data Banzhaf](https://proceedings.mlr.press/v206/wang23e.html)\n",
        "**Parameter:**\n",
        "\n",
        "node_id: The id of the node for which Banzhaf value of edges is calculated\n",
        "\n",
        "**Returns:**\n",
        "\n",
        "A list of tuples, where each tuple consists of the edge and its Banzhaf Value"
      ],
      "metadata": {
        "id": "oXx_CT-wMRoW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfhnxV2XPh13"
      },
      "outputs": [],
      "source": [
        "from itertools import chain, combinations\n",
        "from random import sample\n",
        "from random import choice\n",
        "from random import randint\n",
        "\n",
        "def get_explanation(node_id):\n",
        "  subset, edge_index, mapping, edge_mask = get_edges(data, node_id, HOP_SIZE)\n",
        "  #print(\"Edge index is: \", edge_index)\n",
        "  edge_list = torch.transpose(edge_index, 0, 1).tolist()\n",
        "  #print(edge_list)\n",
        "\n",
        "  for i in edge_list:\n",
        "    #print(i)\n",
        "    cur_from_edge = i[0]\n",
        "    cur_to_edge = i[1]\n",
        "    edge_list.remove([cur_to_edge, cur_from_edge])\n",
        "  #return edge_list\n",
        "\n",
        "  edge_set = set(tuple(x) for x in edge_list)\n",
        "\n",
        "  edgeUtilityDict = dict() # Dictionary containing the following key value pairs (edge: the sum of utilities of coalitions for which the edge is a part)\n",
        "  ret_set = set() #This stores the coalitions that have been sampled\n",
        "  counter = 0\n",
        "\n",
        "  #Initializing the edgeUtilityDict\n",
        "  for tup in edge_set:\n",
        "    edgeUtilityDict[tup] = (0,0)\n",
        "\n",
        "  #print(\"Coalition Count: \", Coalition_Count)\n",
        "  original_prob_vector, original_class = get_node_class_prob(node_id, data.edge_index)\n",
        "  original_prob = original_prob_vector[original_class].item()\n",
        "\n",
        "  coalition_dict=dict()#This stores the utility value of each sampled_coalition\n",
        "  while(len(ret_set) < Coalition_Count):\n",
        "    #print(\"In while\")\n",
        "    #sampled_coalition_list = sample(edge_set, k = randint(2,min(len(edge_set),BUDGET+2)) )\n",
        "    sampled_coalition_list = sample(edge_set,k = min(len(edge_set),BUDGET) )\n",
        "    sampled_coalition_list = tuple(sorted(sampled_coalition_list))\n",
        "    probab_change = get_change_in_class_prob_for_set_of_edges (node_id, sampled_coalition_list)\n",
        "\n",
        "    if((sampled_coalition_list in ret_set) or ((probab_change/original_prob)<THRESHOLD) ):\n",
        "      #print(\"if: \", sampled_coalition)\n",
        "      counter = counter + 1\n",
        "      if(counter==18):\n",
        "        break\n",
        "    else:\n",
        "      #print(\"else: \", sampled_coalition)\n",
        "      ret_set.add(sampled_coalition_list)\n",
        "      counter = 0\n",
        "      # probab_change = get_change_in_class_prob_for_set_of_edges (node_id, sampled_coalition_list)\n",
        "      coalition_dict[sampled_coalition_list] = probab_change\n",
        "      # totalUtility += probab_change\n",
        "\n",
        "  global BANZHAF_TIME\n",
        "  totalUtility = 0 #The sum of utilities of all the coalitions sampled so far\n",
        "  t00 = time.time()\n",
        "  for sampled_coalition_list in ret_set:\n",
        "    probab_change_fake = get_change_in_class_prob_for_set_of_edges (node_id, sampled_coalition_list)\n",
        "    probab_change = coalition_dict[sampled_coalition_list]\n",
        "    totalUtility += probab_change\n",
        "    for tup in sampled_coalition_list:\n",
        "      existingUtilitySum = edgeUtilityDict[tup][0]\n",
        "      existingCoalitionCount = edgeUtilityDict[tup][1]\n",
        "      edgeUtilityDict[tup] = (existingUtilitySum + probab_change, existingCoalitionCount+1)\n",
        "\n",
        "  banzhaf_dict = dict() # Dictionary storing the banzhaf value of each edge\n",
        "\n",
        "  for tup in edgeUtilityDict:\n",
        "    UtilitySum = edgeUtilityDict[tup][0]\n",
        "    CoalitionCount = edgeUtilityDict[tup][1]\n",
        "    if(CoalitionCount == 0 or CoalitionCount == len(ret_set)):\n",
        "      banzhaf_dict[tup] = 0\n",
        "    else:\n",
        "      RemainingUtility = totalUtility - UtilitySum\n",
        "      RemainingCoalitions = len(ret_set) - CoalitionCount\n",
        "      edgeBanzhafValue = (UtilitySum/CoalitionCount) - (RemainingUtility/RemainingCoalitions)\n",
        "      banzhaf_dict[tup] = edgeBanzhafValue\n",
        "\n",
        "  val_banzhaf = sorted(banzhaf_dict.keys(), key= lambda x: banzhaf_dict[x], reverse = True)\n",
        "  explanation_list_banzhaf = []\n",
        "  for edg in val_banzhaf:\n",
        "    explanation_list_banzhaf.append((edg,banzhaf_dict[edg]))\n",
        "  t11 = time.time()\n",
        "  BANZHAF_TIME+=(t11-t00)\n",
        "\n",
        "  return explanation_list_banzhaf\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set the SAMPLING_SIZE variable which holds the number of permutations considered when calculating the shapley value"
      ],
      "metadata": {
        "id": "oI3G33zsLd-u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk3wOe9KBBPf"
      },
      "outputs": [],
      "source": [
        "SAMPLING_SIZE = 50 #Hyperparameter of shapley value: It is the no of permutations using which shapley value is calculated"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to Compute the Shapley Value.\n",
        "Parameter:\n",
        "\n",
        "node_id: The id of the node for which Shapley value of edges is calculated\n",
        "\n",
        "Returns:\n",
        "\n",
        "A list of tuples, where each tuple consists of the edge and its Shapley Value"
      ],
      "metadata": {
        "id": "cMK5dVk_NY-d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qugwrm72AkMt"
      },
      "outputs": [],
      "source": [
        "from itertools import chain, combinations\n",
        "from random import sample\n",
        "from random import choice\n",
        "from random import randint\n",
        "\n",
        "\n",
        "def get_explanation_shapley(node_id):\n",
        "  #print(\"hop size: \", hop_size)\n",
        "  subset, edge_index, mapping, edge_mask = get_edges(data, node_id, HOP_SIZE)\n",
        "  #print(\"Edge index is: \", edge_index)\n",
        "  edge_list = torch.transpose(edge_index, 0, 1).tolist()\n",
        "  #print(edge_list)\n",
        "\n",
        "  for i in edge_list:\n",
        "    #print(i)\n",
        "    cur_from_edge = i[0]\n",
        "    cur_to_edge = i[1]\n",
        "    edge_list.remove([cur_to_edge, cur_from_edge])\n",
        "  #return edge_list\n",
        "\n",
        "  shapely_dict = dict()\n",
        "  for edg in edge_list:\n",
        "    shapely_dict[tuple(edg)] = 0\n",
        "\n",
        "\n",
        "  rng = np.random.default_rng()\n",
        "  val_dictionary = dict()\n",
        "  for counter in range(0, SAMPLING_SIZE):\n",
        "    current_list = []\n",
        "    current_val = 0\n",
        "    perm = rng.permutation(edge_list)\n",
        "    perm = [tuple(x) for x in perm]\n",
        "    #t0 = time.time()\n",
        "    for ind in range(0, len(perm)):\n",
        "      current_list.append(perm[ind])\n",
        "      sorted_current_list = tuple(sorted(current_list))\n",
        "      # print(\"Single entity: \", perm[ind])\n",
        "      # print(\"First n entities:\", tuple(perm[0:ind+1]))\n",
        "      # print(type(tuple(perm[0:ind+1])))\n",
        "      if(sorted_current_list in val_dictionary):\n",
        "        val = val_dictionary[sorted_current_list]\n",
        "      else:\n",
        "        val = get_change_in_class_prob_for_set_of_edges(node_id, current_list)\n",
        "        val_dictionary[sorted_current_list] = val\n",
        "\n",
        "      #print(\"perm[ind]: \", tuple(perm[ind]))\n",
        "      shapely_dict[perm[ind]] += (val - current_val)\n",
        "      current_val = val\n",
        "\n",
        "    # t1 = time.time()\n",
        "    # print(\"Time taken: \",t1-t0)\n",
        "\n",
        "  for edg in shapely_dict:\n",
        "    shapely_dict[edg] /= SAMPLING_SIZE\n",
        "\n",
        "  val = sorted(shapely_dict.keys(), key= lambda x: shapely_dict[x], reverse = True)\n",
        "  explanation_list = []\n",
        "  for edg in val:\n",
        "    explanation_list.append((edg,shapely_dict[edg]))\n",
        "\n",
        "  return explanation_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uncomment the cell below to get an idea of the number of edges within the set hop size for each node in the graph"
      ],
      "metadata": {
        "id": "lAYnQCd4OIxw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQZoYm7f50JP",
        "outputId": "d6d447b3-2262-499b-c0ce-dc434732e89b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101.0\n",
            "88.0\n",
            "33.0\n",
            "72.0\n",
            "67.0\n",
            "158.0\n",
            "61.0\n",
            "101.0\n",
            "117.0\n",
            "62.0\n",
            "85.0\n",
            "26.0\n",
            "62.0\n",
            "63.0\n",
            "73.0\n",
            "47.0\n",
            "28.0\n",
            "65.0\n",
            "41.0\n",
            "20.0\n",
            "30.0\n",
            "32.0\n",
            "44.0\n",
            "24.0\n",
            "43.0\n",
            "19.0\n",
            "37.0\n",
            "26.0\n",
            "42.0\n",
            "16.0\n",
            "22.0\n",
            "16.0\n",
            "23.0\n",
            "16.0\n",
            "10.0\n",
            "18.0\n",
            "36.0\n",
            "15.0\n",
            "14.0\n",
            "22.0\n",
            "27.0\n",
            "20.0\n",
            "25.0\n",
            "43.0\n",
            "19.0\n",
            "21.0\n",
            "13.0\n",
            "18.0\n",
            "9.0\n",
            "28.0\n",
            "16.0\n",
            "17.0\n",
            "18.0\n",
            "14.0\n",
            "9.0\n",
            "14.0\n",
            "19.0\n",
            "9.0\n",
            "6.0\n",
            "12.0\n",
            "9.0\n",
            "15.0\n",
            "15.0\n",
            "21.0\n",
            "17.0\n",
            "18.0\n",
            "17.0\n",
            "16.0\n",
            "19.0\n",
            "28.0\n",
            "13.0\n",
            "7.0\n",
            "27.0\n",
            "13.0\n",
            "10.0\n",
            "10.0\n",
            "21.0\n",
            "8.0\n",
            "13.0\n",
            "12.0\n",
            "15.0\n",
            "17.0\n",
            "12.0\n",
            "8.0\n",
            "12.0\n",
            "14.0\n",
            "9.0\n",
            "25.0\n",
            "10.0\n",
            "11.0\n",
            "16.0\n",
            "7.0\n",
            "17.0\n",
            "24.0\n",
            "11.0\n",
            "11.0\n",
            "7.0\n",
            "9.0\n",
            "15.0\n",
            "10.0\n",
            "10.0\n",
            "8.0\n",
            "12.0\n",
            "12.0\n",
            "11.0\n",
            "13.0\n",
            "18.0\n",
            "11.0\n",
            "21.0\n",
            "4.0\n",
            "9.0\n",
            "9.0\n",
            "7.0\n",
            "9.0\n",
            "9.0\n",
            "23.0\n",
            "6.0\n",
            "10.0\n",
            "12.0\n",
            "14.0\n",
            "13.0\n",
            "9.0\n",
            "10.0\n",
            "11.0\n",
            "18.0\n",
            "11.0\n",
            "12.0\n",
            "10.0\n",
            "12.0\n",
            "12.0\n",
            "6.0\n",
            "14.0\n",
            "15.0\n",
            "12.0\n",
            "9.0\n",
            "7.0\n",
            "8.0\n",
            "9.0\n",
            "13.0\n",
            "11.0\n",
            "11.0\n",
            "14.0\n",
            "11.0\n",
            "13.0\n",
            "7.0\n",
            "15.0\n",
            "13.0\n",
            "12.0\n",
            "9.0\n",
            "8.0\n",
            "8.0\n",
            "8.0\n",
            "6.0\n",
            "9.0\n",
            "7.0\n",
            "10.0\n",
            "10.0\n",
            "10.0\n",
            "8.0\n",
            "15.0\n",
            "8.0\n",
            "14.0\n",
            "7.0\n",
            "7.0\n",
            "8.0\n",
            "11.0\n",
            "6.0\n",
            "9.0\n",
            "7.0\n",
            "9.0\n",
            "7.0\n",
            "10.0\n",
            "5.0\n",
            "5.0\n",
            "11.0\n",
            "8.0\n",
            "6.0\n",
            "11.0\n",
            "7.0\n",
            "8.0\n",
            "6.0\n",
            "6.0\n",
            "5.0\n",
            "9.0\n",
            "7.0\n",
            "7.0\n",
            "5.0\n",
            "9.0\n",
            "8.0\n",
            "7.0\n",
            "9.0\n",
            "11.0\n",
            "9.0\n",
            "10.0\n",
            "9.0\n",
            "13.0\n",
            "10.0\n",
            "7.0\n",
            "9.0\n",
            "8.0\n",
            "12.0\n",
            "5.0\n",
            "16.0\n",
            "6.0\n",
            "9.0\n",
            "9.0\n",
            "8.0\n",
            "8.0\n",
            "7.0\n",
            "9.0\n",
            "5.0\n",
            "8.0\n",
            "7.0\n",
            "12.0\n",
            "13.0\n",
            "6.0\n",
            "8.0\n",
            "6.0\n",
            "12.0\n",
            "11.0\n",
            "7.0\n",
            "7.0\n",
            "10.0\n",
            "6.0\n",
            "6.0\n",
            "7.0\n",
            "9.0\n",
            "6.0\n",
            "5.0\n",
            "6.0\n",
            "7.0\n",
            "7.0\n",
            "6.0\n",
            "7.0\n",
            "8.0\n",
            "7.0\n",
            "6.0\n",
            "6.0\n",
            "7.0\n",
            "10.0\n",
            "8.0\n",
            "9.0\n",
            "10.0\n",
            "7.0\n",
            "5.0\n",
            "7.0\n",
            "10.0\n",
            "9.0\n",
            "8.0\n",
            "6.0\n",
            "10.0\n",
            "9.0\n",
            "5.0\n",
            "6.0\n",
            "9.0\n",
            "8.0\n",
            "8.0\n",
            "5.0\n",
            "5.0\n",
            "5.0\n",
            "6.0\n",
            "9.0\n",
            "8.0\n",
            "6.0\n",
            "8.0\n",
            "6.0\n",
            "6.0\n",
            "7.0\n",
            "10.0\n",
            "10.0\n",
            "7.0\n",
            "9.0\n",
            "6.0\n",
            "7.0\n",
            "6.0\n",
            "12.0\n",
            "5.0\n",
            "10.0\n",
            "8.0\n",
            "7.0\n",
            "10.0\n",
            "8.0\n",
            "5.0\n",
            "6.0\n",
            "7.0\n",
            "6.0\n",
            "10.0\n",
            "7.0\n",
            "6.0\n",
            "7.0\n",
            "6.0\n",
            "7.0\n",
            "6.0\n",
            "5.0\n",
            "5.0\n",
            "7.0\n",
            "5.0\n",
            "8.0\n",
            "5.0\n",
            "12.0\n",
            "5.0\n",
            "5.0\n",
            "2.0\n",
            "2.0\n",
            "3.0\n",
            "5.0\n",
            "6.0\n",
            "2.0\n",
            "2.0\n",
            "4.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "5.0\n",
            "4.0\n",
            "4.0\n",
            "4.0\n",
            "4.0\n",
            "2.0\n",
            "4.0\n",
            "5.0\n",
            "4.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "6.0\n",
            "2.0\n",
            "4.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "2.0\n",
            "5.0\n",
            "4.0\n",
            "5.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "6.0\n",
            "4.0\n",
            "2.0\n",
            "3.0\n",
            "3.0\n",
            "5.0\n",
            "5.0\n",
            "5.0\n",
            "4.0\n",
            "3.0\n",
            "7.0\n",
            "7.0\n",
            "4.0\n",
            "2.0\n",
            "3.0\n",
            "5.0\n",
            "5.0\n",
            "2.0\n",
            "2.0\n",
            "4.0\n",
            "5.0\n",
            "5.0\n",
            "2.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "3.0\n",
            "3.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "2.0\n",
            "5.0\n",
            "4.0\n",
            "4.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "5.0\n",
            "4.0\n",
            "3.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "4.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "5.0\n",
            "4.0\n",
            "4.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "2.0\n",
            "5.0\n",
            "4.0\n",
            "5.0\n",
            "4.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "3.0\n",
            "3.0\n",
            "7.0\n",
            "5.0\n",
            "4.0\n",
            "2.0\n",
            "3.0\n",
            "5.0\n",
            "4.0\n",
            "3.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "2.0\n",
            "3.0\n",
            "3.0\n",
            "5.0\n",
            "6.0\n",
            "3.0\n",
            "3.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "6.0\n",
            "5.0\n",
            "3.0\n",
            "2.0\n",
            "4.0\n",
            "4.0\n",
            "4.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "5.0\n",
            "5.0\n",
            "3.0\n",
            "3.0\n",
            "3.0\n",
            "5.0\n",
            "4.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "5.0\n",
            "4.0\n",
            "2.0\n",
            "3.0\n",
            "5.0\n",
            "4.0\n",
            "3.0\n",
            "3.0\n",
            "4.0\n",
            "6.0\n",
            "5.0\n",
            "3.0\n",
            "3.0\n",
            "4.0\n",
            "6.0\n",
            "4.0\n",
            "3.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "4.0\n",
            "3.0\n",
            "2.0\n",
            "4.0\n",
            "6.0\n",
            "4.0\n",
            "2.0\n",
            "2.0\n",
            "5.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "3.0\n",
            "3.0\n",
            "5.0\n",
            "4.0\n",
            "2.0\n",
            "3.0\n",
            "5.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "4.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "6.0\n",
            "5.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "6.0\n",
            "5.0\n",
            "3.0\n",
            "2.0\n",
            "3.0\n",
            "5.0\n",
            "4.0\n",
            "3.0\n",
            "3.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "4.0\n",
            "4.0\n",
            "3.0\n",
            "5.0\n",
            "5.0\n",
            "3.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "2.0\n",
            "4.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "3.0\n",
            "3.0\n",
            "3.0\n",
            "6.0\n",
            "6.0\n",
            "2.0\n",
            "2.0\n",
            "3.0\n",
            "5.0\n",
            "5.0\n",
            "2.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "6.0\n",
            "3.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "5.0\n",
            "2.0\n",
            "3.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "4.0\n",
            "3.0\n",
            "6.0\n",
            "4.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "7.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "6.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "3.0\n",
            "5.0\n",
            "4.0\n",
            "2.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "5.0\n",
            "5.0\n",
            "3.0\n",
            "6.0\n",
            "5.0\n",
            "5.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "4.0\n",
            "2.0\n",
            "4.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "4.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "2.0\n",
            "4.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "5.0\n",
            "2.0\n",
            "4.0\n",
            "3.0\n",
            "6.0\n",
            "4.0\n",
            "2.0\n",
            "4.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "3.0\n",
            "3.0\n",
            "6.0\n",
            "5.0\n",
            "3.0\n",
            "4.0\n",
            "3.0\n",
            "4.0\n",
            "6.0\n",
            "2.0\n",
            "3.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "5.0\n",
            "4.0\n",
            "2.0\n",
            "4.0\n",
            "6.0\n",
            "4.0\n",
            "3.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "2.0\n",
            "3.0\n",
            "3.0\n",
            "5.0\n",
            "4.0\n",
            "4.0\n",
            "3.0\n",
            "3.0\n",
            "5.0\n",
            "4.0\n",
            "4.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "2.0\n",
            "4.0\n",
            "5.0\n",
            "5.0\n",
            "3.0\n",
            "4.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "3.0\n",
            "3.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "3.0\n",
            "3.0\n",
            "4.0\n",
            "7.0\n",
            "4.0\n",
            "3.0\n",
            "3.0\n",
            "4.0\n",
            "4.0\n",
            "5.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n"
          ]
        }
      ],
      "source": [
        "# for node_id in range((data.x.size())[0]):\n",
        "#   subset, edge_index, mapping, edge_mask = get_edges(data, node_id, 1)\n",
        "#   print((edge_index.size()[1])/2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling 50 % of nodes randomly from the graph. The sampling is done thrice. The cell is commented to perform the sampling only once and store the result later(see the next cell)"
      ],
      "metadata": {
        "id": "hTOSW_hiOa0W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZfR3fI0m_Cl"
      },
      "outputs": [],
      "source": [
        "# numNodes = (data.x.size())[0]\n",
        "# testNodes = []\n",
        "# for i in range(0,3):\n",
        "#   testNodes.append(sample(range(0,numNodes), (int)(numNodes/2) ))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the sampled nodes for use in subsequent runs. Make sure to replace the \"PATH_TO_FILE_THAT_WILL_STORE_THE_SAMPLED_NODES\" with the appropriate path."
      ],
      "metadata": {
        "id": "ikcrKl2PO2oR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kx020KI8VhQV"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "# path = '/content/drive/MyDrive/'\n",
        "# file = open(path + <PATH_TO_FILE_THAT_WILL_STORE_THE_SAMPLED_NODES>, 'wb')\n",
        "# pickle.dump(testNodes, file)\n",
        "# file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the saved sampled nodes. Make sure to replace the \"PATH_TO_FILE_THAT_STORES_THE_SAMPLED_NODES\" with the appropriate path"
      ],
      "metadata": {
        "id": "xvxl5YVkQspx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBqdU8Yth6Fg"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# open a file, where you stored the pickled data\n",
        "path = '/content/drive/MyDrive/'\n",
        "file = open(path+ <PATH_TO_FILE_THAT_STORES_THE_SAMPLED_NODES>, 'rb')\n",
        "\n",
        "# dump information to that file\n",
        "testNodes = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FU_qP_8xQIv"
      },
      "outputs": [],
      "source": [
        "BANZHAF_TIME = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the following lists in the cell below:\n",
        "\n",
        "**thresLis**: The list of thresholds that will be evaluated for a given budget\n",
        "\n",
        "**budgetList**: The list of budgets that will be evaluated\n",
        "\n",
        "Note that the computation for the thresholds and budgets listed above will be done for both Shapley and Banzhaf.\n",
        "\n",
        "Make sure to replace the \"NAME_OF_FILE_THAT_STORES_THE_BANZHAF_AND_SHAPLEY_RESULTS\" with the appropriate path."
      ],
      "metadata": {
        "id": "r_DmuoooRtJg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwAf9vo9x8M-"
      },
      "outputs": [],
      "source": [
        "thresLis = [0, 1e-2, 0.1]\n",
        "budgetList = [3,4,5]\n",
        "FILE_NAME = <NAME_OF_FILE_THAT_STORES_THE_BANZHAF_AND_SHAPLEY_RESULTS>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1tXnnXQSeF7"
      },
      "outputs": [],
      "source": [
        "from statistics import mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "702Jp8du_Mzd"
      },
      "source": [
        "# Average Fidelity for Banzhaf index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLyKy9-uv3Gs"
      },
      "outputs": [],
      "source": [
        "def banFun():\n",
        "  from statistics import mean\n",
        "\n",
        "  total_nodes = data.x.shape[0]\n",
        "  #print(\"Total nodes: \", len(testNodes[0]))\n",
        "  global BANZHAF_TIME\n",
        "  BANZHAF_TIME = 0\n",
        "  cumu_impact_banzhaf = []\n",
        "  # t0 = time.time()\n",
        "  for j in tqdm(testNodes):\n",
        "    run_impacts = []\n",
        "    for i in j:\n",
        "      subset, edge_index, mapping, edge_mask = get_edges(data, i, HOP_SIZE)\n",
        "      '''\n",
        "      if edge_index.size()[1] < 15:\n",
        "        print(i)\n",
        "        impact = get_impact_of_best_set_by_shapley_value(i, BUDGET, HOP_SIZE, SAMPLING_SIZE)\n",
        "        if impact != None: #Discard when explenations weren't generated\n",
        "          cumu_impact.append(impact)\n",
        "      '''\n",
        "      #print(i)\n",
        "      #impact = get_impact_of_best_set_by_shapley_value(i, BUDGET, HOP_SIZE, SAMPLING_SIZE)\n",
        "      explanationList = get_explanation(i)\n",
        "      t0 = time.time()\n",
        "      budgetExplanation = []\n",
        "      for jbud in range(0,min(BUDGET,len(explanationList)) ):\n",
        "        budgetExplanation.append(explanationList[jbud][0])\n",
        "\n",
        "      impact = get_change_in_class_for_set_of_edges (i, budgetExplanation)\n",
        "      # if impact > 0: #Discard when explenations weren't generated\n",
        "      #   cumu_impact.append(impact)\n",
        "      # else:\n",
        "      #   cumu_impact.append(0)\n",
        "      run_impacts.append(impact[1])\n",
        "      t1 = time.time()\n",
        "      BANZHAF_TIME+=t1-t0\n",
        "      # BANZHAF_TIME = BANZHAF_TIME/3.0\n",
        "\n",
        "    cumu_impact_banzhaf.append(mean(run_impacts))\n",
        "\n",
        "\n",
        "  # t1 = time.time()\n",
        "  BANZHAF_TIME = BANZHAF_TIME/3.0\n",
        "  opstr = \"Threshold = \"+str(THRESHOLD)+ \"  Budget= \"+ str(BUDGET) + \"--> Fidelity= \" + str(mean(cumu_impact_banzhaf)) + \" Variance= \" + str(np.var(cumu_impact_banzhaf)) + \" Std Dev = \" + str(np.std(cumu_impact_banzhaf))+ \" Total time taken: \" + str(BANZHAF_TIME)+\"\\n\"\n",
        "  path = '/content/drive/MyDrive/'\n",
        "  file = open(path+ FILE_NAME, 'a')\n",
        "  file.write(opstr)\n",
        "  file.close()\n",
        "  print(\"Threshold = \", THRESHOLD, \"  Budget= \", BUDGET,\"--> Fidelity= \",mean(cumu_impact_banzhaf),\" Variance= \", np.var(cumu_impact_banzhaf), \" Std Dev = \", str(np.std(cumu_impact_banzhaf)), \" Total time taken: \", BANZHAF_TIME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzuwCRj3BpTw"
      },
      "source": [
        "# Average Fidelity for Shapley Value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sk8Xqs440-A6"
      },
      "outputs": [],
      "source": [
        "def shapFun():\n",
        "  from statistics import mean\n",
        "  total_nodes = data.x.shape[0]\n",
        "  #print(\"Total nodes: \", len(testNodes))\n",
        "\n",
        "\n",
        "  cumu_impact = []\n",
        "  t0 = time.time()\n",
        "  for j in tqdm(testNodes):\n",
        "    #run_impacts = [[],[],[],[]]\n",
        "    run_impacts = []\n",
        "    for i in j:\n",
        "\n",
        "      subset, edge_index, mapping, edge_mask = get_edges(data, i, HOP_SIZE)\n",
        "      '''\n",
        "      if edge_index.size()[1] < 15:\n",
        "        print(i)\n",
        "        impact = get_impact_of_best_set_by_shapley_value(i, BUDGET, HOP_SIZE, SAMPLING_SIZE)\n",
        "        if impact != None: #Discard when explenations weren't generated\n",
        "          cumu_impact.append(impact)\n",
        "      '''\n",
        "      #print(i)\n",
        "      #impact = get_impact_of_best_set_by_shapley_value(i, BUDGET, HOP_SIZE, SAMPLING_SIZE)\n",
        "      explanationList = get_explanation_shapley(i)\n",
        "\n",
        "      #print(\"explanationList: \", explanationList)\n",
        "      # for bud in [3,5,6,7]:\n",
        "      #   budgetExplanation = []\n",
        "      #   for jbud in range(0,min(bud,len(explanationList)) ):\n",
        "      #     budgetExplanation.append(explanationList[jbud][0])\n",
        "\n",
        "      #   impact = get_change_in_class_for_set_of_edges (i, budgetExplanation)\n",
        "      #   if(bud==3):\n",
        "      #     run_impacts[0].append(impact[1])\n",
        "      #   else:\n",
        "      #     run_impacts[bud-4].append(impact[1])\n",
        "\n",
        "      budgetExplanation = []\n",
        "      for jbud in range(0,min(BUDGET,len(explanationList)) ):\n",
        "        budgetExplanation.append(explanationList[jbud][0])\n",
        "\n",
        "      impact = get_change_in_class_for_set_of_edges (i, budgetExplanation)\n",
        "      run_impacts.append(impact[1])\n",
        "\n",
        "    # mytup=()\n",
        "    # for myvar in range(0,len(run_impacts)):\n",
        "    #   mytup = mytup + (mean(run_impacts[myvar]),)\n",
        "\n",
        "    # cumu_impact.append(mytup)\n",
        "    cumu_impact.append(mean(run_impacts))\n",
        "\n",
        "  t1 = time.time()\n",
        "  ttaken = (t1-t0)/3.0\n",
        "  print(\"Total time taken: \", ttaken)\n",
        "\n",
        "  opstr = \"  Budget= \"+ str(BUDGET) + \"--> Fidelity= \" + str(mean(cumu_impact)) + \" Variance= \" + str(np.var(cumu_impact)) + \" Std Dev = \" + str(np.std(cumu_impact))+ \" Total time taken: \" + str(ttaken)+\"\\n\"\n",
        "  path = '/content/drive/MyDrive/'\n",
        "  file = open(path+ FILE_NAME, 'a')\n",
        "  file.write(opstr)\n",
        "  file.close()\n",
        "  print(\"Budget= \", BUDGET,\"--> Fidelity= \",mean(cumu_impact), \" Variance= \" + str(np.var(cumu_impact)), \" Std Dev = \", np.std(cumu_impact), \" Total time taken: \", ttaken)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The cell below runs a script to calculate average fidelity and time for different budget and threshold(For Banzhaf) combinations for Banzhaf and Shapley"
      ],
      "metadata": {
        "id": "GIplCl1pTarU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw6Sdo7BvjDc",
        "outputId": "446c0f59-8dd6-4477-f6e4-2d09d81e403f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]<ipython-input-31-904e0fe4a473>:51: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  sampled_coalition_list = sample(edge_set,k = min(len(edge_set),BUDGET) )\n",
            "100%|██████████| 3/3 [1:01:01<00:00, 1220.58s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold =  0   Budget=  3 --> Fidelity=  0.38761904761904764  Variance=  0.0003773242630385495  Std Dev =  0.019424836242258246  Total time taken:  429.56480884552\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [24:10<00:00, 483.49s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold =  0.01   Budget=  3 --> Fidelity=  0.38476190476190475  Variance=  0.0003555555555555552  Std Dev =  0.018856180831641256  Total time taken:  117.74410947163899\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [09:10<00:00, 183.46s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold =  0.1   Budget=  3 --> Fidelity=  0.4142857142857143  Variance=  0.0003646258503401359  Std Dev =  0.01909517871977468  Total time taken:  30.517156839370728\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [36:20<00:00, 726.67s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time taken:  726.6727422078451\n",
            "Budget=  3 --> Fidelity=  0.43523809523809526  Variance= 0.00024126984126984058  Std Dev =  0.015532863266952445  Total time taken:  726.6727422078451\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [1:20:22<00:00, 1607.65s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold =  0   Budget=  4 --> Fidelity=  0.3580952380952381  Variance=  0.00029569160997732397  Std Dev =  0.01719568579549312  Total time taken:  609.4899380207062\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [49:34<00:00, 991.42s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold =  0.01   Budget=  4 --> Fidelity=  0.36095238095238097  Variance=  0.00020317460317460342  Std Dev =  0.014253932901995977  Total time taken:  297.73747714360553\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [15:41<00:00, 313.74s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold =  0.1   Budget=  4 --> Fidelity=  0.3771428571428571  Variance=  0.0001687074829931972  Std Dev =  0.01298874447331986  Total time taken:  65.35936609903972\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [34:15<00:00, 685.33s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time taken:  685.3312514623007\n",
            "Budget=  4 --> Fidelity=  0.38476190476190475  Variance= 0.0002412698412698412  Std Dev =  0.015532863266952465  Total time taken:  685.3312514623007\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [1:25:52<00:00, 1717.40s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold =  0   Budget=  5 --> Fidelity=  0.3819047619047619  Variance=  0.0005678004535147389  Std Dev =  0.023828563815612953  Total time taken:  686.825798590978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [1:05:27<00:00, 1309.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold =  0.01   Budget=  5 --> Fidelity=  0.3819047619047619  Variance=  0.0006603174603174606  Std Dev =  0.025696642977584845  Total time taken:  431.499365568161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [25:44<00:00, 514.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold =  0.1   Budget=  5 --> Fidelity=  0.3961904761904762  Variance=  0.0007419501133786851  Std Dev =  0.02723876123061923  Total time taken:  125.47339677810669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [32:58<00:00, 659.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time taken:  659.4078682263693\n",
            "Budget=  5 --> Fidelity=  0.38476190476190475  Variance= 0.0006603174603174599  Std Dev =  0.025696642977584835  Total time taken:  659.4078682263693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for scriptBudget in budgetList:\n",
        "  BUDGET = scriptBudget\n",
        "\n",
        "  path = '/content/drive/MyDrive/'\n",
        "  file = open(path+ FILE_NAME, 'a')\n",
        "  file.write(\"Banzhaf Results:\\n\")\n",
        "  file.close()\n",
        "\n",
        "  for scriptThres in thresLis:\n",
        "    THRESHOLD = scriptThres\n",
        "    banFun()\n",
        "\n",
        "  path = '/content/drive/MyDrive/'\n",
        "  file = open(path+ FILE_NAME, 'a')\n",
        "  file.write(\"\\nShapley Results:\\n\")\n",
        "  file.close()\n",
        "\n",
        "  shapFun()\n",
        "\n",
        "  path = '/content/drive/MyDrive/'\n",
        "  file = open(path+ FILE_NAME, 'a')\n",
        "  file.write(\"\\n\\n\")\n",
        "  file.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}